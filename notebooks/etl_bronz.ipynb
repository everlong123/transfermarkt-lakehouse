{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b755e94-291a-4e46-8bbd-44a6e6389c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing players\n",
      "Silver: players done\n",
      "Processing clubs\n",
      "Silver: clubs done\n",
      "Processing transfers\n",
      "Silver: transfers done\n",
      "Processing performance from appearances\n",
      "Silver: performance done\n",
      "\n",
      "Silver dataset summary:\n",
      "players: count = 32601, cols = 24\n",
      "clubs: count = 439, cols = 17\n",
      "transfers: count = 79646, cols = 10\n",
      "performance: count = 1706806, cols = 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, lower, year, current_date, concat_ws, when\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Khởi tạo SparkSession + cấu hình MinIO\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Transfermarkt ETL - Bronze to Silver (Real DataRaw)\")\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin12345\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "BRONZE = \"s3a://transfermarkt-bronze\"\n",
    "SILVER = \"s3a://transfermarkt-silver\"\n",
    "\n",
    "# --- 2. Players ---\n",
    "print(\"Processing players\")\n",
    "df_players = spark.read.csv(f\"{BRONZE}/players.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_players_clean = (\n",
    "    df_players\n",
    "    .withColumn(\"name\", when(col(\"name\").isNotNull(), col(\"name\"))\n",
    "                .otherwise(concat_ws(\" \", trim(col(\"first_name\")), trim(col(\"last_name\")))))\n",
    "    .dropna(subset=[\"name\"])\n",
    "    .withColumn(\"name\", trim(lower(col(\"name\"))))\n",
    ")\n",
    "\n",
    "if \"date_of_birth\" in df_players_clean.columns:\n",
    "    df_players_clean = df_players_clean.withColumn(\n",
    "        \"age\", year(current_date()) - year(col(\"date_of_birth\"))\n",
    "    )\n",
    "\n",
    "df_players_clean.write.mode(\"overwrite\").parquet(f\"{SILVER}/players\")\n",
    "print(\"Silver: players done\")\n",
    "\n",
    "# --- 3. Clubs ---\n",
    "print(\"Processing clubs\")\n",
    "df_clubs = spark.read.csv(f\"{BRONZE}/clubs.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_clubs_clean = (\n",
    "    df_clubs\n",
    "    .withColumnRenamed(\"name\", \"club_name\")\n",
    "    .dropna(subset=[\"club_name\"])\n",
    "    .withColumn(\"club_name\", trim(lower(col(\"club_name\"))))\n",
    "    .dropDuplicates([\"club_name\"])\n",
    ")\n",
    "\n",
    "df_clubs_clean.write.mode(\"overwrite\").parquet(f\"{SILVER}/clubs\")\n",
    "print(\"Silver: clubs done\")\n",
    "\n",
    "# --- 4. Transfers ---\n",
    "print(\"Processing transfers\")\n",
    "df_transfers = spark.read.csv(f\"{BRONZE}/transfers.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_transfers_clean = (\n",
    "    df_transfers\n",
    "    .withColumnRenamed(\"from_club_name\", \"club_from\")\n",
    "    .withColumnRenamed(\"to_club_name\", \"club_to\")\n",
    "    .withColumnRenamed(\"transfer_season\", \"season\")\n",
    "    .withColumnRenamed(\"transfer_fee\", \"fee\")\n",
    "    .withColumn(\"club_from\", trim(lower(col(\"club_from\"))))\n",
    "    .withColumn(\"club_to\", trim(lower(col(\"club_to\"))))\n",
    "    .withColumn(\"season\", col(\"season\").cast(\"string\"))\n",
    "    .withColumn(\"fee\", when(col(\"fee\").isNotNull(), col(\"fee\")).otherwise(0))\n",
    "    .dropna(subset=[\"player_id\"])\n",
    ")\n",
    "\n",
    "df_transfers_clean.write.mode(\"overwrite\").parquet(f\"{SILVER}/transfers\")\n",
    "print(\"Silver: transfers done\")\n",
    "\n",
    "# --- 5. Performance ---\n",
    "print(\"Processing performance from appearances\")\n",
    "df_appear = spark.read.csv(f\"{BRONZE}/appearances.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# giữ các cột thích hợp nếu có\n",
    "cols = [c for c in [\"player_id\", \"goals\", \"assists\", \"minutes_played\"] if c in df_appear.columns]\n",
    "df_perf_clean = (\n",
    "    df_appear.select(cols)\n",
    "    .dropna(subset=[\"player_id\"])\n",
    "    .withColumn(\"goals\", col(\"goals\").cast(\"int\"))\n",
    "    .withColumn(\"assists\", col(\"assists\").cast(\"int\"))\n",
    "    .withColumn(\"minutes_played\", col(\"minutes_played\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "df_perf_clean.write.mode(\"overwrite\").parquet(f\"{SILVER}/performance\")\n",
    "print(\"Silver: performance done\")\n",
    "\n",
    "# --- 6. Kiểm tra kết quả Silver ---\n",
    "print(\"\\nSilver dataset summary:\")\n",
    "for t in [\"players\", \"clubs\", \"transfers\", \"performance\"]:\n",
    "    df = spark.read.parquet(f\"{SILVER}/{t}\")\n",
    "    print(f\"{t}: count = {df.count()}, cols = {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a7591-938f-4461-896e-f2765e2bbca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
