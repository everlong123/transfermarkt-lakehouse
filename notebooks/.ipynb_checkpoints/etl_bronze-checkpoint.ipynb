{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c323d-868b-4d0e-abd5-605d358f6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Notebook: etl_bronze_to_silver.ipynb\n",
    "# Ng∆∞·ªùi th·ª±c hi·ªán: SV1 - Data Engineer\n",
    "# M·ª•c ti√™u: L√†m s·∫°ch d·ªØ li·ªáu Bronze ‚Üí Silver (Transfermarkt)\n",
    "# ============================================================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, lower, year, current_date, concat_ws, when\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Kh·ªüi t·∫°o SparkSession\n",
    "# -------------------------------\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Transfermarkt ETL - Bronze to Silver\")\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin12345\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. ƒê∆∞·ªùng d·∫´n\n",
    "# -------------------------------\n",
    "BRONZE = \"s3a://transfermarkt-bronze\"\n",
    "SILVER = \"s3a://transfermarkt-silver\"\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Players\n",
    "# -------------------------------\n",
    "print(\"‚ñ∂ ƒêang x·ª≠ l√Ω: players.csv\")\n",
    "df_players = spark.read.csv(f\"{BRONZE}/players.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_players_clean = (\n",
    "    df_players\n",
    "    .withColumn(\"name\", when(col(\"name\").isNotNull(), col(\"name\"))\n",
    "                .otherwise(concat_ws(\" \", trim(col(\"first_name\")), trim(col(\"last_name\")))))\n",
    "    .dropna(subset=[\"name\"])\n",
    "    .withColumn(\"name\", trim(lower(col(\"name\"))))\n",
    ")\n",
    "\n",
    "if \"date_of_birth\" in df_players_clean.columns:\n",
    "    df_players_clean = df_players_clean.withColumn(\n",
    "        \"age\", year(current_date()) - year(col(\"date_of_birth\"))\n",
    "    )\n",
    "\n",
    "df_players_clean.write.mode(\"overwrite\").parquet(f\"{SILVER}/players\")\n",
    "print(\"‚úÖ Ghi Silver: players\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Clubs\n",
    "# -------------------------------\n",
    "print(\"‚ñ∂ ƒêang x·ª≠ l√Ω: clubs.csv\")\n",
    "df_clubs = spark.read.csv(f\"{BRONZE}/clubs.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_clubs_clean = (\n",
    "    df_clubs\n",
    "    .withColumnRenamed(\"name\", \"club_name\")\n",
    "    .withColumn(\"club_name\", trim(lower(col(\"club_name\"))))\n",
    "    .dropna(subset=[\"club_name\"])\n",
    "    .dropDuplicates([\"club_name\"])\n",
    ")\n",
    "\n",
    "df_clubs_clean.write.mode(\"overwrite\").parquet(f\"{SILVER}/clubs\")\n",
    "print(\"‚úÖ Ghi Silver: clubs\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Transfers\n",
    "# -------------------------------\n",
    "print(\"‚ñ∂ ƒêang x·ª≠ l√Ω: transfers.csv\")\n",
    "df_transfers = spark.read.csv(f\"{BRONZE}/transfers.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_transfers_clean = (\n",
    "    df_transfers\n",
    "    .withColumn(\"club_from\", trim(lower(col(\"club_from\"))))\n",
    "    .withColumn(\"club_to\", trim(lower(col(\"club_to\"))))\n",
    "    .withColumn(\"fee\", when(col(\"fee\").isNotNull(), col(\"fee\")).otherwise(0))\n",
    "    .withColumn(\"season\", col(\"season\").cast(\"string\"))\n",
    "    .dropna(subset=[\"player_id\"])\n",
    ")\n",
    "\n",
    "df_transfers_clean.write.mode(\"overwrite\").parquet(f\"{SILVER}/transfers\")\n",
    "print(\"‚úÖ Ghi Silver: transfers\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Performance (t·ª´ appearances.csv ho·∫∑c player_valuations.csv)\n",
    "# -------------------------------\n",
    "print(\"‚ñ∂ ƒêang x·ª≠ l√Ω: appearances.csv\")\n",
    "df_perf = spark.read.csv(f\"{BRONZE}/appearances.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Gi·ªØ c·ªôt quan tr·ªçng (tu·ª≥ theo dataset c·ªßa b·∫°n)\n",
    "cols_perf = [c for c in [\n",
    "    \"player_id\", \"game_id\", \"goals\", \"assists\", \"minutes_played\", \"yellow_cards\", \"red_cards\"\n",
    "] if c in df_perf.columns]\n",
    "\n",
    "df_perf_clean = (\n",
    "    df_perf.select(cols_perf)\n",
    "    .dropna(subset=[\"player_id\"])\n",
    "    .withColumn(\"goals\", col(\"goals\").cast(\"int\"))\n",
    "    .withColumn(\"assists\", col(\"assists\").cast(\"int\"))\n",
    "    .withColumn(\"minutes_played\", col(\"minutes_played\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "df_perf_clean.write.mode(\"overwrite\").parquet(f\"{SILVER}/performance\")\n",
    "print(\"‚úÖ Ghi Silver: performance\")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Ki·ªÉm tra nhanh\n",
    "# -------------------------------\n",
    "print(\"\\nüéØ Silver layer ƒë√£ s·∫µn s√†ng:\")\n",
    "for tbl in [\"players\", \"clubs\", \"transfers\", \"performance\"]:\n",
    "    df = spark.read.parquet(f\"{SILVER}/{tbl}\")\n",
    "    print(f\"{tbl}: {df.count()} b·∫£n ghi | {len(df.columns)} c·ªôt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
