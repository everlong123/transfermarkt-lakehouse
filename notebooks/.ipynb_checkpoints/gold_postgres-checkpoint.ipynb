{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77eafe26-45bf-4057-ae2d-ec9cadb2cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark ready!\n",
      "‚ñ∂ Reading Parquet: s3a://transfermarkt-gold/dim_players\n",
      "üíæ Writing to PostgreSQL: public.dim_players\n",
      "‚úÖ Done: dim_players\n",
      "‚ñ∂ Reading Parquet: s3a://transfermarkt-gold/dim_clubs\n",
      "üíæ Writing to PostgreSQL: public.dim_clubs\n",
      "‚úÖ Done: dim_clubs\n",
      "‚ñ∂ Reading Parquet: s3a://transfermarkt-gold/fact_transfers\n",
      "üíæ Writing to PostgreSQL: public.fact_transfers\n",
      "‚úÖ Done: fact_transfers\n",
      "‚ñ∂ Reading Parquet: s3a://transfermarkt-gold/fact_performance\n",
      "üíæ Writing to PostgreSQL: public.fact_performance\n",
      "‚úÖ Done: fact_performance\n",
      "\n",
      "üéâ ALL GOLD TABLES EXPORTED TO POSTGRESQL SUCCESSFULLY!\n",
      "‚û° Superset now can connect and create dashboards.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# EXPORT GOLD (Parquet in MinIO) ‚Üí PostgreSQL (for Superset)\n",
    "# =============================================================\n",
    " \n",
    "from pyspark.sql import SparkSession\n",
    " \n",
    "# ----------------------------\n",
    "# 1) Spark Session\n",
    "# ----------------------------\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Export Gold to PostgreSQL\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    .config(\"spark.jars.packages\",\n",
    "        \t\"org.apache.hadoop:hadoop-aws:3.3.4,\"\n",
    "        \t\"com.amazonaws:aws-java-sdk-bundle:1.12.262,\"\n",
    "        \t\"org.postgresql:postgresql:42.7.3\")   # JDBC driver\n",
    "    .getOrCreate()\n",
    ")\n",
    " \n",
    "# ----------------------------\n",
    "# 2) C·∫•u h√¨nh MinIO (S3A)\n",
    "# ----------------------------\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"admin\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"admin12345\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\")\n",
    " \n",
    "print(\"‚úÖ Spark ready!\")\n",
    " \n",
    "# ----------------------------\n",
    "# 3) ƒê∆∞·ªùng d·∫´n Gold Layer (Parquet)\n",
    "# ----------------------------\n",
    "GOLD_BASE = \"s3a://transfermarkt-gold\"\n",
    " \n",
    "tables = {\n",
    "    \"dim_players\": f\"{GOLD_BASE}/dim_players\",\n",
    "    \"dim_clubs\": f\"{GOLD_BASE}/dim_clubs\",\n",
    "    \"fact_transfers\": f\"{GOLD_BASE}/fact_transfers\",\n",
    "    \"fact_performance\": f\"{GOLD_BASE}/fact_performance\",\n",
    "}\n",
    " \n",
    "# ----------------------------\n",
    "# 4) Th√¥ng tin PostgreSQL (docker-compose)\n",
    "# ----------------------------\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/metastore\"\n",
    "jdbc_properties = {\n",
    "    \"user\": \"hive\",\n",
    "    \"password\": \"metastore\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    " \n",
    "# ----------------------------\n",
    "# 5) EXPORT T·ª™ PARQUET ‚Üí POSTGRESQL\n",
    "# ----------------------------\n",
    "for table_name, path in tables.items():\n",
    "    try:\n",
    "        print(f\"‚ñ∂ Reading Parquet: {path}\")\n",
    "        df = spark.read.parquet(path)\n",
    " \n",
    "        print(f\"üíæ Writing to PostgreSQL: public.{table_name}\")\n",
    "        (\n",
    "        \tdf.write\n",
    "        \t.format(\"jdbc\")\n",
    "        \t.option(\"url\", jdbc_url)\n",
    "        \t.option(\"dbtable\", f\"public.{table_name}\")\n",
    "        \t.option(\"user\", jdbc_properties[\"user\"])\n",
    "        \t.option(\"password\", jdbc_properties[\"password\"])\n",
    "        \t.option(\"driver\", jdbc_properties[\"driver\"])\n",
    "        \t.mode(\"overwrite\")  # ho·∫∑c 'append'\n",
    "        \t.save()\n",
    "        )\n",
    " \n",
    "        print(f\"‚úÖ Done: {table_name}\")\n",
    " \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Skipped {table_name} | Error: {e}\")\n",
    " \n",
    "print(\"\\nüéâ ALL GOLD TABLES EXPORTED TO POSTGRESQL SUCCESSFULLY!\")\n",
    "print(\"‚û° Superset now can connect and create dashboards.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aadad7-82fb-482f-b203-9d3a9032fd91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
